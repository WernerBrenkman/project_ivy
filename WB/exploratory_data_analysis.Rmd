---
title: "project ivy: House Prices (Kaggle) - EDA"
output: github_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
require(knitr)
source('src/ini.R')
source('src/load.R')
source('src/transform.R')
```

## Overview


[House Prices: Advanced Regression Techniques](https://www.kaggle.com/c/house-prices-advanced-regression-techniques)

## Let's get a feel for the data

Let's load the data and implement the rules based on **data_description.txt** and inspect the data

```{r overview, echo=FALSE, warning=FALSE}
# dimensions
# -----------
dims = dim(df)
names(dims) = c('Rows', 'Cols')
print(dims)

# NA's
# -----------
print_na_cols = function(){
  na_cols = lapply(df, function(x){sum(is.na(x))}) %>%
  unlist() %>%
  as.data.frame() %>%
  rownames_to_column()
names(na_cols) = c('Variable', 'Missing')
na_cols %>%
  filter(Missing > 0) %>%
  print()
}
print_na_cols()
```

There are 21 variables containing NA's. Note the following:

*  **SalesPrice** is missing because the **test** data was merged with the **train** data. That leaves us with 20 variables containing NA's.
*  **GarageYrBlt** will be NA if there is no garage on the property

Let's visualise missing
```{r impute_viz, echo=FALSE, warning=FALSE, message=FALSE}
require(VIM)
df %>%
  select(-GarageYrBlt, -SalePrice, -Id, -set_id) %>%
  aggr(.)

```


```{r imputed, echo=FALSE, warning=FALSE}
source('src/impute.R')
print_na_cols()
```

## Visualisation

Notice **SalePrice** vs **SalePriceLog**. We'll be using **SalePriceLog** from now on.

```{r viz, echo=FALSE, fig.width=10, fig.asp=.25}

p = ggplot(train) + theme_bw()
multiplot(p + geom_histogram(aes(x = SalePrice)),
          p + geom_histogram(aes(x = SalePriceLog)),
          cols = 2)

```

### Numeric variables
Let's get an overview of the numeric variables
```{r, fig.width=14, fig.asp=1, echo=FALSE, warning=FALSE, message=FALSE}
draw_corplot = function(var, scale_x_log10 = FALSE){
  if(scale_x_log10){  
    p + geom_point(aes_string(x = var, y = 'SalePriceLog'), alpha = .5) + ggtitle(var) + scale_x_log10()
  }else{  
    p + geom_point(aes_string(x = var, y = 'SalePriceLog'), alpha = .5) + ggtitle(var)
  }
}
plotlist = lapply(train, function(x){ifelse(class(x) %in% c('integer', 'numeric'), 1, NA)}) %>% unlist()
plotlist = names(plotlist)[which(plotlist == 1)]
plotlist = plotlist[plotlist != 'Id']
plotlist = lapply(plotlist, function(x){draw_corplot(x)})
multiplot(cols = 5, plotlist = plotlist)
```

When reading **data_descr.txt** it is clear that some variables are highly correlated purely by definition. Let's explore those in detail and decide which to keep.

```{r, echo=FALSE, warning=FALSE, message=FALSE}
cor_def_vars = c('YearBuilt', 'GarageYrBlt', 'GarageCars', 'GarageArea', 'YearRemodAdd')

cor(train[, cor_def_vars], use = "complete.obs")

multiplot(cols = 2, plotlist = list(
  p + geom_point(aes_string(x = 'YearBuilt', y = 'GarageYrBlt')),
  p + geom_point(aes_string(x = 'GarageCars', y = 'GarageArea'))
))

```
From the above we can see that there is a very high correlation between **YearBuilt** & **GarageYrBlt** as well as **GarageCars** & **GarageArea**. Another point to note is that each of **GarageYrBlt**, **GarageCars** & **GarageArea** indicates the lack of a garage on the property. Further we will use only **YearBuilt** and **GarageArea** as these variables contains info regarding the age of the property (and garage), if there is in fact a garage and its size.

It would make sense that bigger houses are more expensive. Let's cluster all area related variables and assess the impact of area on **SalePrice**

```{r, echo=FALSE, warning=FALSE, message=FALSE}
area_vars = c('LotArea', 
              # 'MasVnrArea', 
              # 'BsmtUnfSF', 
              'TotalBsmtSF', 
              'GrLivArea',
              'GarageArea',
              # 'SalePriceLog',
              'OverallQual'
              # 'WoodDeckSF', 
              # 'OpenPorchSF', 
              # 'EnclosedPorch', 
              # 'x_3SsnPorch', 
              # 'ScreenPorch', 
              # 'PoolArea'
              )
df_area = scale(train[, area_vars], center = F)

K = lapply(1:20, function(k){kmeans(x = df_area, centers = k, nstart = 100)$tot.withinss}) %>%
  unlist()
plot(K)

km_area = kmeans(x = df_area, centers = 4, nstart = 100)
train$cl_area = km_area$cluster
cor(train[, c('cl_area', 'SalePriceLog')])

p = ggplot(train) + theme_bw()
p + geom_point(aes(x = ExterQual, y = SalePriceLog, color = as.factor(cl_area)), alpha=.5)
p + geom_point(aes(x = LandSlope, y = SalePriceLog, color = as.factor(cl_area)), alpha=.5)

require(ggfortify)
autoplot(km_area, data = df_area)

```


```{r remove_vars, echo=FALSE, warning=FALSE, message=FALSE}
source('src/feature_eng.R')
```



### Categorical variables

```{r, fig.width= 14, fig.asp=1, echo=FALSE}
draw_boxplot = function(var){
  p + geom_boxplot(aes_string(x = var, y = 'SalePriceLog')) + ggtitle(var)
}
plotlist = lapply(train, function(x){ifelse(class(x) %in% c('factor'), 1, NA)}) %>% unlist()
plotlist = names(plotlist)[which(plotlist == 1)]
plotlist = lapply(plotlist, function(x){draw_boxplot(x)})
multiplot(cols = 5, plotlist = plotlist)
# bp_vars = c(factor_vars, ord_factor_vars)
# plotlist = lapply(bp_vars, function(x){draw_boxplot(x)})
```
When reading **data_descr.txt** it is clear that some variables are highly correlated purely by definition. Let's explore those in detail and decide which to keep.
