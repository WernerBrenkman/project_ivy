---
title: "data_modeling - Gabriella"
output: rmarkdown::github_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# Data Modeling
Now that we have explored our dataset, developed better insight into the features and completed our EDA. Let's move onto our Data Modeling to predict the SalePrice. 

In our approach predicting the response variable, we will consider a few models. 
Firstly, we will employ a saturated linear regression model. Afterwhich we will explore a few itertaions of this model. 
We'll also consider a model built on the features as highlighted by the Random Forest explored in EDA. 
Finally, we will consider a Lasso Regression Model. 

## Split Data
In preparing to model our dataset, we will split the data again as to ensure that any new features we may have added are included correctly - just as a precautionary measure. 
```{r}
var_remove = c('set_id', 'SalePrice', 'SaleCondition', 'SaleType', 'MSSubClass')

train$NeighPrice = df$NeighPrice[1:1460]
test$NeighPrice = df$NeighPrice[1461:2919]
train$MSSubClassPrice = df$MSSubClassPrice[1:1460]
test$MSSubClassPrice = df$MSSubClassPrice[1461:2919]

train[, var_remove] = NULL
test[, var_remove] = NULL
df[, var_remove] = NULL
```

## Vanilla Saturdated Model
As mentioned, our first model is built on a vanilla saturdated linear regression model. 
This model makes use of all features identified in the dataset, including any additional features we might have added. 
```{r}
library(Metrics)

#### Model 
# ---------------------
lr_saturated_model = lm(formula = SalePriceLog ~ ., 
                        data = train)

lr_sat_sum = summary(lr_saturated_model)
sat_pred = predict(lr_saturated_model, test)

sat_RMSE = sqrt(mean((train$SalePriceLog - lr_saturated_model$fitted.values)^2))

#### Export Results 
# ---------------------
output_sat = cbind(test$Id, 10^sat_pred)
colnames(output_sat) = c("Id", "SalePrice")
write.csv(output_sat, file = "saturated_submission.csv", row.names = FALSE)

```
RMSE for Saturated Model (Training Error) = 0.0439
The Saturated Model resulted in a RMSE (Test Error) = 0.14063

## 'My intuition' Model
Seperate model features considered in prediction:
```{r}
#### Model 
# ---------------------
#model_var = c('SalePrice', 'SalePriceLog', 'TotalBsmtSF', 'NeighPrice', 'OverallQual', 'OverallCond', #'YearBuilt', 'GrLivArea', 'BsmtQual', 'KitchenQual', 'HeatingQC', 'FireplaceQu', 'GarageArea', 'CentralAir', #'MSSubClassPrice')

model_var = c('SalePriceLog', 'TotalBsmtSF', 'NeighPrice', 'OverallQual', 'OverallCond', 'YearBuilt', 'GrLivArea', 'BsmtQual', 'KitchenQual', 'HeatingQC', 'FireplaceQu', 'GarageArea', 'CentralAir', 'LotArea', 'LotShape', 'BsmtFinSF1', 'X1stFlrSF')

model_lin = train[ , model_var]

f = SalePriceLog ~ .
lr_int_model = lm(formula = f,
              data = model_lin)

lr_int_sum = summary(lr_int_model)

#### Variable Importance 
# ---------------------
library(caret)
varImp(lr_int_model)

lr_int_pred = predict(lr_int_model, test)
int_mse = sqrt(mean((train$SalePriceLog - lr_int_model$fitted.values)^2))

#### Anova Test 
# ---------------------
anova(lr_int_model, lr_saturated_model)

#### Export Results 
# ---------------------
output_int = cbind(test$Id, 10^sat_pred)
colnames(output_int) = c("Id", "SalePrice")
write.csv(output_int, file = "intuitive_submission.csv", row.names = FALSE)
```
RMSE for intuition model (training error) = 0.062499
RMSE (Test error) = 0.13997
Although the training error for the Intuition Model is higher, from the Anova F-Test it seems that variables beyond what has been identified in the reduced (intuition) model do not contribute significant information to the SalePrice of Houses. This is proved by the p-value which is < 0.05.

From the variable importance plot, let's try and remove variables that do not contribute signifcantly to SalePrice (are of less importance). In our 2nd round, let's remove: TotalBsmtSF, LotShape.
Our second round of the model above resulted in RMSE (training error) = 0.06251, and a Test RMSE of 0.14012 - thus doing worse (and thus not included here) than our first intuitive model.

## Random Forest Model
Let's model on the top 15 variables as identified by the Random Forest method, identified in EDA.  
```{r}
#### Visualize Random Forest diagram
# ---------------------
forest

#### Model
# ---------------------
model_for = c('SalePriceLog', 'GrLivArea', 'Neighborhood', 'OverallQual', 'X1stFlrSF', 'TotalBsmtSF', 'BsmtFinSF1', 'GarageArea', 'X2ndFlrSF', 'LotArea', 'OverallCond', 'BsmtFinType1', 'YearRemodAdd', 'ExterQual', 'FireplaceQu', 'GarageType')

model_for = train[ , model_for]

f = SalePriceLog ~ .
lr_for_model = lm(formula = f,
              data = model_for)

lr_for_sum = summary(lr_for_model)
#varImp(lr_for_model)

lr_for_pred = predict(lr_for_model, test)
for_mse = sqrt(mean((train$SalePriceLog - lr_for_model$fitted.values)^2))

#### Export Results 
# ---------------------
output_for = cbind(test$Id, 10^lr_for_pred)
colnames(output_for) = c("Id", "SalePrice")
write.csv(output_for, file = "forest_submission.csv", row.names = FALSE)

```
RMSE for intuition model (training error) = 0.060959
Test Error scored by the Random Forest model =  0.14457, not performing better than the intuitive model.


## Lasso Regression Model
Now, let's perform a Lasso Regression Model. 
```{r}
# Help: https://github.com/praneethkvs/house-prices/blob/master/house-prices.R
library(caret)
#### Model
# ---------------------

tr.control = trainControl(method="repeatedcv", number = 10, repeats = 10)
lambdas = seq(1,0,-.001)
tune_grid = expand.grid(alpha=1,lambda=c(1,0.1,0.05,0.01,seq(0.009,0.001,-0.001), 0.00075,0.0005,0.0001))

# train function with class formula
lasso_model = train(SalePriceLog ~ . , 
                    data = train,
                    method = "glmnet",
                    metric = "RMSE",
                    maximize = FALSE,
                    trControl = tr.control
                    # tuneGrid = tune_grid
                    )

lasso_pred = 10^(predict(lasso_model, newdata = test))-1
lasso_model$results

#### Export Results 
# ---------------------
write.csv(data.frame(Id=test$Id,SalePrice=lassopreds),"lasso_submission.csv",row.names = FALSE)
```
Our Lasso Regression model was the best performing prediction model and resulted in a RMSE Test Error of 0.13361. 





